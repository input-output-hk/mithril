"use strict";(globalThis.webpackChunkmithril_doc=globalThis.webpackChunkmithril_doc||[]).push([[8249],{59675(e){e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"10","metadata":{"permalink":"/doc/adr/10","source":"@site/adr/010-http-status-code.md","title":"10. Specific Mithril Http status code\\n","description":"Status","date":"2025-03-21T00:00:00.000Z","tags":[{"inline":true,"label":"Accepted","permalink":"/doc/adr/tags/accepted"}],"readingTime":0.6,"hasTruncateMarker":false,"authors":[{"name":"Mithril Team","socials":{},"key":null,"page":null}],"frontMatter":{"slug":"10","title":"10. Specific Mithril Http status code\\n","authors":[{"name":"Mithril Team"}],"tags":["Accepted"],"date":"2025-03-21T00:00:00.000Z"},"unlisted":false,"nextItem":{"title":"9. Database migration squashing\\n","permalink":"/doc/adr/9"}},"content":"## Status\\n\\nAccepted\\n\\n## Context\\n\\nIn exchanges between the signer and the aggregator, we need to retrieve the reason why a request was unsuccessful.\\nError handling will depend on the specific functional case of Mithril.\\nWe could have reused existing HTTP codes, but they are too general and could be returned for cases other than the one we wish to isolate.\\n\\n## Decision\\n\\nWe therefore decided to return specific error codes when we need to identify the functional case.\\nWe start at 450 for client error codes and at 550 for server error codes.\\n\\n## Consequences\\n\\nSpecific Mithril HTTP status code on server error should be between 550 and 599.\\nFor client error the HTTP status code should be between 450 and 499."},{"id":"9","metadata":{"permalink":"/doc/adr/9","source":"@site/adr/009-database-migration-squashing.md","title":"9. Database migration squashing\\n","description":"Status","date":"2025-03-13T00:00:00.000Z","tags":[{"inline":true,"label":"Accepted","permalink":"/doc/adr/tags/accepted"}],"readingTime":0.84,"hasTruncateMarker":false,"authors":[{"name":"Mithril Team","socials":{},"key":null,"page":null}],"frontMatter":{"slug":"9","title":"9. Database migration squashing\\n","authors":[{"name":"Mithril Team"}],"tags":["Accepted"],"date":"2025-03-13T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"10. Specific Mithril Http status code\\n","permalink":"/doc/adr/10"},"nextItem":{"title":"8. Standardize JSON Message Testing\\n","permalink":"/doc/adr/8"}},"content":"## Status\\n\\nAccepted\\n\\n## Context\\n\\nOver time, many database migrations have accumulated in Mithril nodes. Since these migrations are applied sequentially, the resulting database schema has become difficult to understand and maintain.\\n\\n## Decision\\n\\nTo address this, the team decided to implement migration squashing once too many migrations have accumulated for a store. This process consolidates all existing migrations into a single, equivalent migration.\\n\\n## Consequences\\n\\n- This applies to the migrations of all Mithril node stores\\n- A squashed migration will be applied when a database is initialized for the first time\\n- A squashed migration must be optional and should only run if it has not been previously applied with the equivalent migration sequence\\n- Some nodes may have only partially applied the equivalent sequence of migrations and cannot apply the squashed migration immediately:\\n  - They must first run the migration using the latest distribution that does not include the squashed migration, ensuring their database is prepared to apply it\\n  - This distribution is associated with a squashed migration to provide a smooth user experience."},{"id":"8","metadata":{"permalink":"/doc/adr/8","source":"@site/adr/008-standardize-json-messages-testing.md","title":"8. Standardize JSON Message Testing\\n","description":"Status","date":"2025-01-14T00:00:00.000Z","tags":[{"inline":true,"label":"Accepted","permalink":"/doc/adr/tags/accepted"}],"readingTime":2.2,"hasTruncateMarker":false,"authors":[{"name":"Mithril Team","socials":{},"key":null,"page":null}],"frontMatter":{"slug":"8","title":"8. Standardize JSON Message Testing\\n","authors":[{"name":"Mithril Team"}],"tags":["Accepted"],"date":"2025-01-14T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"9. Database migration squashing\\n","permalink":"/doc/adr/9"},"nextItem":{"title":"7. Standardize log output\\n","permalink":"/doc/adr/7"}},"content":"## Status\\n\\nAccepted\\n\\n## Context\\n\\n- To ensure backward compatibility and correctness of JSON messages exchanged between nodes, we need a standardized approach\\n  to test the deserialization of these messages.\\n- Golden testing is a technique where the expected output (golden data) is stored and used to verify the correctness of\\n  the system\'s output. This approach helps in detecting unintended changes in the output and ensures that the system\\n  behaves as expected over time.\\n- By using golden testing for JSON message deserialization, we can ensure that any changes to the message structures are\\n  backward compatible and that the deserialization process yields the expected results.\\n- We have been using golden testing for JSON messages in the project, but the approach used ad-hoc versions that did not\\n  correspond to any OpenAPI versions, making it difficult to track the changes and maintain backward compatibility.\\n\\n## Decision\\n\\nWe will standardize the testing of JSON messages by following the steps below:\\n\\nWhen adding a new JSON message structure, the following steps should be taken:\\n\\n- Introduce a constant `CURRENT_JSON` string containing an exhaustive example of the JSON currently exchanged between nodes.\\n- Implement a `golden_message_current` method that returns the representation of the `CURRENT_JSON` using the current structure.\\n- Implement a `test_current_json_deserialized_into_current_message` test that checks that deserializing the `CURRENT_JSON` into the current structure yields the output stored in `golden_message_current`.\\n\\nWhen modifying an existing JSON message structure, if backward compatibility is maintained, the following steps should be taken:\\n\\n- Given `X_Y_ZZ` is the version of the OpenAPI before the change:\\n  - Create a copy of the previous version structure as it was before the backward-compatible change, suffixed with `UntilVX_Y_ZZ`, e.g., `CertificateMessageUntilV0_1_32`.\\n  - Create a copy the `golden_message_current` method named `golden_message_until_open_api_X_Y_ZZ`, and update its return type to the version structure suffixed with `UntilVX_Y_ZZ`.\\n  - Implement a `test_current_json_deserialized_into_message_supported_until_open_api_X_Y_ZZ` test that checks that deserializing the `CURRENT_JSON` into the previous structure yields the output stored in `golden_message_until_open_api_X_Y_ZZ`.\\n- Modify the `CURRENT_JSON` string to reflect the new structure.\\n- Modify the `golden_message_current` method to return the representation of the `CURRENT_JSON` using the new structure.\\n\\nWhen modifying an existing JSON message structure, if backward compatibility is not maintained, the following steps should be taken:\\n\\n- Modify the `CURRENT_JSON` string to reflect the new structure.\\n- Modify the `golden_message_current` method to return the representation of the `CURRENT_JSON` using the new structure.\\n- Remove all `golden_message_until_open_api_X_Y_ZZ` method and the corresponding structure and tests, as they are no longer relevant.\\n\\n## Consequences\\n\\n- Ensures that any changes to the JSON message structure are backward compatible.\\n- Provides a clear and standardized approach to testing JSON message deserialization.\\n- Helps maintain the integrity and reliability of the communication between nodes.\\n- Requires maintaining multiple versions of message structures and corresponding tests, which may increase the maintenance overhead."},{"id":"7","metadata":{"permalink":"/doc/adr/7","source":"@site/adr/007-standardize-log-output.md","title":"7. Standardize log output\\n","description":"Status","date":"2024-04-07T00:00:00.000Z","tags":[{"inline":true,"label":"Accepted","permalink":"/doc/adr/tags/accepted"}],"readingTime":0.92,"hasTruncateMarker":false,"authors":[{"name":"Mithril Team","socials":{},"key":null,"page":null}],"frontMatter":{"slug":"7","title":"7. Standardize log output\\n","authors":[{"name":"Mithril Team"}],"tags":["Accepted"],"date":"2024-04-07T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"8. Standardize JSON Message Testing\\n","permalink":"/doc/adr/8"},"nextItem":{"title":"6. Errors implementation Standard\\n","permalink":"/doc/adr/6"}},"content":"## Status\\n\\nAccepted\\n\\n## Context\\n\\n- [ADR 2](/adr/2) is not completely relevant now, we have migrated recently the logs in the client to `stderr`. Only the result of the command execution is in `stdout`. This makes it possible to exploit the result, see our [blog post](/dev-blog/2024/02/26/mithril-client-cli-output-breaking-change).\\n- Mithril aggregator logs are always redirected to `stdout` but it mixes 2 types of CLI commands, some of which would benefit from the logs output to `stderr`.\\n- Mithril aggregator and Mithril client CLI have not a consistent log strategy, that\'s why we need to standardize them.\\n\\n## Decision\\n\\n- For commands that provide a result or execute an action, logs are sent to `stderr`. Only the result of the command is sent to `stdout`.\\n- For commands that launch a program without an expected result (server), logs are sent to `stdout`.\\n\\n## Consequences\\n\\n- End users who use `stdout` logs would have a breaking change. They will have to retrieve the logs that come from `stderr` in addition.\\n- Commands `genesis`, `era` and `tools` from Mithril aggregator now send their logs to `stderr`."},{"id":"6","metadata":{"permalink":"/doc/adr/6","source":"@site/adr/006-errors-implementation.md","title":"6. Errors implementation Standard\\n","description":"Status","date":"2023-09-27T00:00:00.000Z","tags":[{"inline":true,"label":"Accepted","permalink":"/doc/adr/tags/accepted"}],"readingTime":5.54,"hasTruncateMarker":false,"authors":[{"name":"Mithril Team","socials":{},"key":null,"page":null}],"frontMatter":{"slug":"6","title":"6. Errors implementation Standard\\n","authors":[{"name":"Mithril Team"}],"tags":["Accepted"],"date":"2023-09-27T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"7. Standardize log output\\n","permalink":"/doc/adr/7"},"nextItem":{"title":"5. Use rfc3339 for date formatting\\n","permalink":"/doc/adr/5"}},"content":"## Status\\n\\nAccepted\\n\\n## Context\\n\\nError handling is difficult with Rust:\\n\\n- Many ways of implementing them with different crates ([`thiserror`](https://crates.io/crates/thiserror), [`anyhow`](https://crates.io/crates/anyhow), ...)\\n- No exception like handling of errors\\n- No stack trace or context available by default\\n- Backtrace uniquely when a panic occurs and if `RUST_BACKTRACE` environment variable is set to `1` or `full`\\n\\nWe think the errors handling should be done in a consistent way in the project.\\nThus we have worked on a standardization of their implementation and tried to apply it to the whole repository.\\nThis has enabled us to have a clear vision of the do and don\'t that we intend to summarize in this ADR.\\n\\n## Decision\\n\\n_Therefore_\\n\\n- We have decided to use `thiserror` and `anyhow` crates to implement the errors:\\n  - [`thiserror`](https://crates.io/crates/thiserror) is used to create module or domain errors that come from our developments and can be easily identified (as they are strongly typed).\\n  - [`anyhow`](https://crates.io/crates/anyhow) is used to add a context to an error triggered by a sub-system. The context is a convenient way to get \'stack trace\' like debug information.\\n\\nHere is a [Rust playground](https://play.rust-lang.org/?version=stable&mode=debug&edition=2021&gist=bf667c443696beb90106f6ae627a57b9) that summarizes the usage of `thiserror`:\\n\\n```rust\\n#[allow(unused_imports)]\\nuse anyhow::{anyhow, Context, Result}; // 1.0.71\\nuse thiserror::Error; // 1.0.43\\n\\n#[derive(Error, Debug)]\\n#[error(\\"Codec error: {msg}\\")]\\npub struct CodecError {\\n    msg: String,\\n    #[source] // optional if field name is `source`\\n    source: anyhow::Error,\\n}\\n\\n#[derive(Error, Debug)]\\npub enum DomainError {\\n    #[error(\\"Error with codec: {0:?}\\")]\\n    CodecWithOnlyDebug(CodecError),\\n\\n    #[error(\\"Error with codec\\")]\\n    CodecWithSource(#[source] CodecError),\\n\\n    #[error(\\"Error with codec: {0}\\")]\\n    CodecWithoutAnything(CodecError),\\n\\n    #[error(\\"Anyhow error: {0:?}\\")]\\n    AnyhowWrapWithOnlyDebug(anyhow::Error),\\n\\n    #[error(\\"Anyhow error\\")]\\n    AnyhowWrapWithSource(#[source] anyhow::Error),\\n\\n    #[error(\\"Anyhow error: {0}\\")]\\n    AnyhowWrapWithoutAnything(anyhow::Error),\\n}\\n\\nfn anyhow_result() -> Result<()> {\\n    \\"invalid_number\\"\\n        .parse::<u64>()\\n        .map(|_| ())\\n        .with_context(|| \\"Reading database failure\\")\\n}\\n\\nfn thiserror_struct() -> Result<(), CodecError> {\\n    Err(CodecError {\\n        msg: \\"My message\\".to_string(),\\n        source: anyhow!(\\"Could not decode config\\"),\\n    })?;\\n    Ok(())\\n}\\n\\nfn print_error(title: &str, error: anyhow::Error) {\\n    println!(\\"{title:-^80}\\");\\n    println!(\\"{error:?}\\\\n\\",);\\n}\\n\\nfn main() {\\n    println!(\\"1 - Printing errors from enum variant that contains a error struct\\\\n\\");\\n    // Debug the inner error struct: \\"normal\\" debug without the anyhow touch\\n    print_error(\\n        \\"DomainError::CodecWithOnlyDebug\\",\\n        anyhow!(DomainError::CodecWithOnlyDebug(\\n            thiserror_struct().unwrap_err()\\n        )),\\n    );\\n    // marking the inner error struct as source: anyhow will be able to make a\\n    // stacktrace out of this error. Nice !\\n    print_error(\\n        \\"DomainError::CodecWithSource\\",\\n        anyhow!(DomainError::CodecWithSource(\\n            thiserror_struct().unwrap_err()\\n        )),\\n    );\\n    // without debugging the inner error: only show the error text\\n    print_error(\\n        \\"DomainError::CodecWithoutAnything\\",\\n        anyhow!(DomainError::CodecWithoutAnything(\\n            thiserror_struct().unwrap_err()\\n        )),\\n    );\\n\\n    println!(\\"\\\\n2 - Printing errors from enum variant that contains a anyhow error\\\\n\\");\\n    // using only debug: the first two errors of the stack will be merged\\n    print_error(\\n        \\"DomainError::AnyhowWrapWithOnlyDebug\\",\\n        anyhow!(DomainError::AnyhowWrapWithOnlyDebug(\\n            anyhow_result().with_context(|| \\"context\\").unwrap_err()\\n        )),\\n    );\\n    // using #[source] attribute: each error of the stack will have a line\\n    print_error(\\n        \\"DomainError::AnyhowWrapWithSource\\",\\n        anyhow!(DomainError::AnyhowWrapWithSource(\\n            anyhow_result().with_context(|| \\"context\\").unwrap_err()\\n        )),\\n    );\\n    // without debug nor source: only the uppermost error is print\\n    print_error(\\n        \\"DomainError::AnyhowWrapWithoutAnything\\",\\n        anyhow!(DomainError::AnyhowWrapWithoutAnything(\\n            anyhow_result().with_context(|| \\"context\\").unwrap_err()\\n        )),\\n    );\\n}\\n\\n```\\n\\nWhich will output errors this way:\\n\\n```\\n1 - Printing errors from enum variant that contains a error struct\\n\\n------------------------DomainError::CodecWithOnlyDebug-------------------------\\nError with codec: CodecError { msg: \\"My message\\", source: Could not decode config }\\n\\n--------------------------DomainError::CodecWithSource--------------------------\\nError with codec\\n\\nCaused by:\\n    0: Codec error: My message\\n    1: Could not decode config\\n\\n-----------------------DomainError::CodecWithoutAnything------------------------\\nError with codec: Codec error: My message\\n\\n\\n2 - Printing errors from enum variant that contains a anyhow error\\n\\n----------------------DomainError::AnyhowWrapWithOnlyDebug----------------------\\nAnyhow error: context\\n\\nCaused by:\\n    0: Reading database failure\\n    1: invalid digit found in string\\n\\n-----------------------DomainError::AnyhowWrapWithSource------------------------\\nAnyhow error\\n\\nCaused by:\\n    0: context\\n    1: Reading database failure\\n    2: invalid digit found in string\\n\\n---------------------DomainError::AnyhowWrapWithoutAnything---------------------\\nAnyhow error: context\\n```\\n\\nHere is a [Rust playground](https://play.rust-lang.org/?version=stable&mode=debug&edition=2021&gist=90f962ab001d2ea0321fc5da0d4ec0f1) that summarizes the usage of the `context` feature form `anyhow`:\\n\\n```rust\\n#[allow(unused_imports)]\\nuse anyhow::{anyhow, Context, Result}; // 1.0.71\\n\\nfn read_db() -> Result<()> {\\n    \\"invalid_number\\"\\n        .parse::<u64>()\\n        .map(|_| ())\\n        .with_context(|| \\"Reading database failure\\")\\n}\\n\\nfn do_work() -> Result<()> {\\n    read_db().with_context(|| \\"Important work failed while reading database\\")\\n}\\n\\nfn do_service_work() -> Result<()> {\\n    do_work().with_context(|| \\"Service could not do the important work\\")\\n}\\n\\nfn main() {\\n    let error = do_service_work().unwrap_err();\\n\\n    println!(\\"Error string:\\\\n {error}\\\\n\\\\n\\");\\n    println!(\\"Error debug:\\\\n {error:?}\\\\n\\\\n\\");\\n    println!(\\"Error pretty:\\\\n {error:#?}\\\\n\\\\n\\");\\n}\\n\\n```\\n\\nWhich will output errors this way:\\n\\n```\\nError string:\\n Service could not do the important work\\n\\n\\nError debug:\\n Service could not do the important work\\n\\nCaused by:\\n    0: Important work failed while reading database\\n    1: Reading database failure\\n    2: invalid digit found in string\\n\\n\\nError pretty:\\n Error {\\n    context: \\"Service could not do the important work\\",\\n    source: Error {\\n        context: \\"Important work failed while reading database\\",\\n        source: Error {\\n            context: \\"Reading database failure\\",\\n            source: ParseIntError {\\n                kind: InvalidDigit,\\n            },\\n        },\\n    },\\n}\\n```\\n\\n## Consequences\\n\\n- We have defined the following aliases that should be used by default:\\n  - `StdResult`: the default result that should be returned by a function (unless a more specific type is required).\\n  - `StdError`: the default error that should be used (unless a more specific type is required).\\n\\n```rust\\n/* Code extracted from mithril-common::lib.rs */\\n/// Generic error type\\npub type StdError = anyhow::Error;\\n\\n/// Generic result type\\npub type StdResult<T> = anyhow::Result<T, StdError>;\\n```\\n\\n- The function that returns an error from a sub-system should systematically add a context to the error with the `with_context` method, in order to provide clear stack traces and ease debugging.\\n\\n- When printing an `StdError` we should use the debug format without the pretty modifier, ie:\\n\\n```rust\\nprintln!(\\"Error debug:\\\\n {error:?}\\\\n\\\\n\\");\\n```\\n\\n- When wrapping an error in a `thiserror` enum variant we should use the `source` attribute that will provide a clearer stack trace:\\n\\n```rust\\n/// Correct usage with `source` attribute\\n#[derive(Error, Debug)]\\npub enum DomainError {\\n    #[error(\\"Anyhow error\\")]\\n    AnyhowWrapWithSource(#[source] StdError),\\n}\\n```\\n\\n```rust\\n/// Incorrect usage without `source` attribute\\n#[derive(Error, Debug)]\\npub enum DomainError {\\n    #[error(\\"Anyhow error: {0}\\")]\\n    AnyhowWrapWithoutAnything(StdError),\\n}\\n```\\n\\n- Here are some tips on how to discriminate between creating a new error using `thiserror` or using an `StdResult`:\\n  - If you raise an anyhow error which only contains a string this means that you are creating a new error that doesn\'t come from a sub-system. In that case you should create a type using `thiserror` intead, ie:\\n\\n```rust\\n// Avoid\\nreturn Err(anyhow!(\\"my new error\\"));\\n\\n// Prefer\\n#[derive(Debug,Error)]\\npub enum MyError {\\n  MyNewError\\n}\\nreturn Err(MyError::MyNewError);\\n```\\n\\n- (_Still undecided_) You should avoid wrapping a `StdError` in a `thiserror` type. This **breaks** the stack trace and makes it really difficult to retrieve the innermost errors using `downcast_ref`. When the `thiserror` type is itself wrapped in a `StdError` afterward, you would have to `downcast_ref` twice: first to get the `thiserror` type and then to get the innermost error.\\n  This should be restricted to the topmost errors of our system (ie the state machine errors)."},{"id":"5","metadata":{"permalink":"/doc/adr/5","source":"@site/adr/005-use-rfc3339-for-dates.md","title":"5. Use rfc3339 for date formatting\\n","description":"Status","date":"2023-06-21T00:00:00.000Z","tags":[{"inline":true,"label":"Accepted","permalink":"/doc/adr/tags/accepted"}],"readingTime":1.25,"hasTruncateMarker":false,"authors":[{"name":"Mithril Team","socials":{},"key":null,"page":null}],"frontMatter":{"slug":"5","title":"5. Use rfc3339 for date formatting\\n","authors":[{"name":"Mithril Team"}],"tags":["Accepted"],"date":"2023-06-21T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"6. Errors implementation Standard\\n","permalink":"/doc/adr/6"},"nextItem":{"title":"4. Mithril Network Upgrade Strategy\\n","permalink":"/doc/adr/4"}},"content":"## Status\\n\\nAccepted\\n\\n## Context\\n\\nPreviously, on the Mithril project we did not have a preferred format for the dates in our applications, leading to\\nmultiple formats being used.\\n\\nFor example when querying a certificate from an aggregator, the `initiated_at` field did not specify the timezone,\\ntimezone that could be found in the `sealed_at` field:\\n\\n```json\\n{\\n  \\"initiated_at\\": \\"2023-05-26T00:02:23\\",\\n  \\"sealed_at\\": \\"2023-05-26T00:03:23.998753492Z\\"\\n}\\n```\\n\\nSame problem in our databases where a date could be stored without timezone and milliseconds (ie: `2023-06-13 16:35:28`)\\nin one table column and with them in another (ie: `2023-06-13T16:35:28.143292875Z`).\\n\\nThe [RFC 3339](https://datatracker.ietf.org/doc/html/rfc3339) is a widely used, easily readable, mostly numeric (no\\ntranslation is needed to parse the day or the month), format. Also, it always includes the timezone meaning that our\\nclient can convert such date to their local time if needed.\\n\\n## Decision\\n\\n_Therefore_\\n\\n- We commit to use **RFC 3339** compatible date and time whenever we need to store or show a date and time.\\n\\n## Consequences\\n\\n- All dates and time must use a dedicated type in the application, ie: the `DateTime<Utc>` type from\\n  [chrono](https://crates.io/crates/chrono) crate.\\n  - This means that dates must **never** be stored in our types using Strings.\\n- Internally, we will always use the **UTC timezone**, to avoid useless conversions between timezones.\\n- Users or scripts querying dates from our applications or from our databases will be able to parse all of them using\\n  the same format."},{"id":"4","metadata":{"permalink":"/doc/adr/4","source":"@site/adr/004-mithril-network-update-strategy.md","title":"4. Mithril Network Upgrade Strategy\\n","description":"Status","date":"2023-01-05T00:00:00.000Z","tags":[{"inline":true,"label":"Accepted","permalink":"/doc/adr/tags/accepted"}],"readingTime":4.25,"hasTruncateMarker":false,"authors":[{"name":"Mithril Team","socials":{},"key":null,"page":null}],"frontMatter":{"slug":"4","title":"4. Mithril Network Upgrade Strategy\\n","authors":[{"name":"Mithril Team"}],"tags":["Accepted"],"date":"2023-01-05T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"5. Use rfc3339 for date formatting\\n","permalink":"/doc/adr/5"},"nextItem":{"title":"3. Release process and versioning\\n","permalink":"/doc/adr/3"}},"content":"## Status\\n\\nAccepted\\n\\n## Context\\n\\nWhen we will run Mithril on mainnet there will be thousands of signers running. Upgrading the version of the nodes has an impact as different versions of API, messages, signature may lead to loss of a significant part of the signers population over one epoch or more. In any case we must prevent a gap in the certificate chain while upgrading critical parts.\\n\\nWe need to be able to keep enough of signer nodes and the aggregator able to work together in order to produce at least one certificate per epoch.\\n\\nExamples of such changes:\\n\\n- change in the message structure\\n- change in the cryptographic algorithm\\n- change in communication channels\\n\\n## Decision\\n\\nIn order to synchronize all nodes behavior transition, the Release Team will define Eras that start at a given Cardano Epoch and lasts until the next Era begins. When nodes detect an Era change, they switch from old to new behavior hence all transitioning at almost the same time.\\n\\n## Consequences\\n\\n### Release Team\\n\\nThe release team is the team responsible of releasing new versions of Mithril software. The **Release Team** will be responsible to set the Epoch at which **Eras** change using an **Era Activation Marker**. In order to be able to determine when the new Era will begin, the Release Team has to know what is the share of the total Mithril stake that can run the new behavior. Signer node software versions has to be **monitored**.\\n\\n### Version monitoring\\n\\nThe Release Team must be aware of the software version run by the Signer nodes and their associated stake. The version is going to be added to all HTTP headers in inter-node communication. In a first step, the Aggregator nodes will record this information, and provide the mapping of stakes to Signer nodes.\\n\\nThis configuration works in the case where there is a centralized Aggregator Node (as it is today). In the future, there may be several Aggregator nodes working in a decentralized manner. This would mean having a separate monitoring service, and also monitor the aggregators node versions.\\n\\n### Era Activation Marker\\n\\nAn Era Activation Marker is an information shared among all the nodes. For every upgrade, there are two phases:\\n\\n- a first marker is set on the blockchain that just indicates a new Era will start soon and softwares shall be updated.\\n- a second marker is set that specifies the Epoch when they must switch from old to new behavior.\\n\\nEvery Era Activation Marker will be a transaction in the Cardano blockchain. This implies the nodes must be able to read transactions of the blockchain. Era Activation Markers can be of the same type, the first maker does not hold any Epoch information whereas the second does.\\n\\nNode will check the blockchain for Markers at startup and for every new Epoch. When a node detects a Marker, it will warn the user if it does not support the incoming Era that he must upgrade his node. If the node detects it does not support the current Era, it will stop working with an explicit error message. To ease that operation, Era Activation Marker will be made sortable.\\n\\n### Behavior Switch\\n\\nThe nodes must be able to switch from one behavior to another when the Era Epoch is reached. This means the software must embed both behaviors. The switch is developed as a one time operation, there is no rollback mechanism available. Once the Epoch is transitioned and the switch has occurred, a new software release can remove the old behavior from the codebase.\\n\\n```mermaid\\nsequenceDiagram\\n    actor Release Team\\n    actor User\\n    Release Team--xChain: New Era coming soon.\\n    Note over Chain: new Epoch\\n    Old Node->>Chain: What is the latest marker?\\n    Chain->>Old Node: Era change soon\\n    New Node->>Chain: What is the last marker?\\n    Chain->>New Node: Era change soon\\n    Note over New Node: upgrade\\n    Loop every Epoch\\n        Note over Chain: new Epoch\\n        Old Node->>Chain: What is the last marker?\\n        Chain->>Old Node: Era change soon\\n        Old Node->>User: \u26a0\ufe0f new Era incoming, please update node\\n        New Node->>Chain: What is the last marker?\\n        Chain->>New Node: Era change soon\\n    end\\n    Release Team--xChain: New Era start at Epoch XX.\\n    Loop every Epoch\\n        Note over Chain: new Epoch\\n        Old Node->>Chain: What is the last marker?\\n        Chain->>Old Node: Era change at Epoch XX\\n        Old Node->>User: \u26a0\ufe0f new Era incoming, please update node\\n        New Node->>Chain: What is the last marker?\\n        Chain->>New Node: Era change at Epoch XX\\n    end\\n    Note over Chain: Epoch XX\\n    Note over Old Node,New Node: new Era\\n    New Node->>Chain: What is the last marker?\\n    Chain->>New Node: Era change at Epoch XX\\n    Note over New Node: switch behavior\\n    Old Node->>Chain: What is the last marker?\\n    Chain->>Old Node: Era change at Epoch XX\\n    Old Node->>User: \ud83d\udc80 unsupported Era, quit.\\n```\\n\\n### Client-side era awareness\\n\\nThe Mithril clients do not have access to a Cardano node and therefore can not read the Era Activation Markers stored on chain. As a consequence, they rely on the current era run by the aggregator, by using the era advertised by its `/status` route."},{"id":"3","metadata":{"permalink":"/doc/adr/3","source":"@site/adr/003-release/index.md","title":"3. Release process and versioning\\n","description":"Status","date":"2022-10-21T00:00:00.000Z","tags":[{"inline":true,"label":"Accepted","permalink":"/doc/adr/tags/accepted"}],"readingTime":2.96,"hasTruncateMarker":false,"authors":[{"name":"Mithril Team","socials":{},"key":null,"page":null}],"frontMatter":{"slug":"3","title":"3. Release process and versioning\\n","authors":[{"name":"Mithril Team"}],"tags":["Accepted"],"date":"2022-10-21T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"4. Mithril Network Upgrade Strategy\\n","permalink":"/doc/adr/4"},"nextItem":{"title":"2. Use simple structured logging\\n","permalink":"/doc/adr/2"}},"content":"## Status\\n\\nAccepted\\n\\n## Context\\n\\nIn order to deliver regularly the software to our users, we should implement a release process based on a predictable versioning scheme.\\n\\n### Versioning\\n\\nA Release Version determines a distribution of determined node versions and underlying libraries.\\n\\n- Our softwares must be able to interact seamlessly with other Mithril software.\\n- Our softwares must be able to be hosted on crates.io.\\n- Our softwares must clearly indicate compatibility with other Mithril components to end users.\\n\\n### Release process\\n\\nA Release is a software package that is built once and then promoted from the testing environment to the production environment. It can be signed.\\n\\n- Keep it simple.\\n- Automated as much as possible: all points not requiring human decision shall be automated.\\n- Minimize the mean time to release.\\n\\n## Decision\\n\\nThere are 3 versioned layers in the Mithril stack:\\n\\n- HTTP API protocol to ensure compatibility in the communication between nodes (use Semver).\\n- Crate version: each node & library has its own version (use Semver). The commit digest is automatically added to the version by the CI pipeline.\\n- Release Version: the distribution version (use version scheme **YYWW.patch** | **YYWW.patch-name**). The VERSION file is computed by the pipeline from the tag release.\\n\\nThe documentation is tied to a Release Version.\\n\\n### Release Process\\n\\nStarting just after a new release has been made:\\n\\n1. Develop on a dedicated development branch.\\n1. When merging PR on main: update the `Cargo.toml` files with version of the updated nodes.\\n1. Once merged, the CI creates an `unstable` tag & release which is deployed on testing environment.\\n1. Push a tag using the distribution version format on this commit with a `-prerelease` suffix.\\n1. The CI gets the built artifacts associated with this commit and generates a named pre-release which is deployed on `pre-release` for testing.\\n1. Push a tag using the distribution version format on this commit without the `-prerelease` suffix.\\n1. The CI gets the built artifacts associated with this commit and generates a named release which is deployed on `pre-release` for testing.\\n1. In the release GitHub interface, edit the newly generated release, uncheck the `This is a pre-release` checkbox.\\n1. The CI gets the built artifacts associated with this commit and generates a named release which is deployed on `release`.\\n1. Create a commit:\\n   1. to promote the documentation website from future to current.\\n   1. to update the SQL schema with alterations from the previous release.\\n\\n[![Release Process](./img/release_process.jpg)](./img/release_process.jpg)\\n\\n### Hotfix Release\\n\\n\u200b\\nIn case of a blocking issue (following a distribution release) on the release environment that requires an immediate fix:\\n\u200b\\n\\n1. Create a branch on the last release tag with the following scheme: `hotfix/{last_distribution-version}.{last_patch_number + 1}`.\\n1. Development of the fix is done on this branch.\\n1. After each commit on this branch, the CI creates an `unstable` tag & release which is not deployed on testing environment (testing must be done on an ad hoc environment manually created).\\n1. Push a tag on the branch last commit using the branch distribution version with a `-hotfix` suffix.\\n1. The CI gets the built artifacts associated with this commit and generates a named pre-release which is deployed on `pre-release` for testing.\\n1. In the release GitHub interface, edit the newly generated release, uncheck the `This is a pre-release` checkbox.\\n1. The CI gets the built artifacts associated with this commit and generates a named release which is deployed on `release`.\\n1. Merge the hotfix branch on main branch (and adapt the changes if they are not compatible with the current main branch)."},{"id":"2","metadata":{"permalink":"/doc/adr/2","source":"@site/adr/002-use-structured-logging.md","title":"2. Use simple structured logging\\n","description":"Status","date":"2022-04-24T00:00:00.000Z","tags":[{"inline":true,"label":"Superseded","permalink":"/doc/adr/tags/superseded"}],"readingTime":0.76,"hasTruncateMarker":false,"authors":[{"name":"Mithril Team","socials":{},"key":null,"page":null}],"frontMatter":{"slug":"2","title":"2. Use simple structured logging\\n","authors":[{"name":"Mithril Team"}],"tags":["Superseded"],"date":"2022-04-24T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"3. Release process and versioning\\n","permalink":"/doc/adr/3"},"nextItem":{"title":"1. Record Architecture Decisions\\n","permalink":"/doc/adr/1"}},"content":"## Status\\n\\nSuperseded by [ADR 7](/adr/7)\\n\\n## Context\\n\\n- Logs are a critical tool for operating any software system, enabling [observability](https://cloud.google.com/architecture/devops/devops-measurement-monitoring-and-observability) of the system.\\n- Following [12 Factor Apps](https://12factor.net/logs) principles, providing the needed components and tools to be able to configure logging and monitoring should not be the responsibility of the software components\\n\\n## Decision\\n\\n_Therefore_\\n\\n- Each component of the system use [Structured logging](https://www.sumologic.com/glossary/structured-logging/) using documented and standardised JSON format for its logs\\n- Logs are always emitted to `stdout` of the process the component is part of\\n\\n## Consequences\\n\\n- The schema of the logged items should be properly documented in a JSON schema\\n- It is the responsibility of the node operator to consume the logs and process them\\n- We use existing libraries to provide needed log infrastructure, like [slog](https://zsiciarz.github.io/24daysofrust/book/vol2/day4.html) for Rust"},{"id":"1","metadata":{"permalink":"/doc/adr/1","source":"@site/adr/001-use-adr.md","title":"1. Record Architecture Decisions\\n","description":"Status","date":"2022-04-21T00:00:00.000Z","tags":[{"inline":true,"label":"Accepted","permalink":"/doc/adr/tags/accepted"}],"readingTime":0.57,"hasTruncateMarker":false,"authors":[{"name":"Mithril Team","socials":{},"key":null,"page":null}],"frontMatter":{"slug":"1","title":"1. Record Architecture Decisions\\n","authors":[{"name":"Mithril Team"}],"tags":["Accepted"],"date":"2022-04-21T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"2. Use simple structured logging\\n","permalink":"/doc/adr/2"}},"content":"## Status\\n\\nAccepted\\n\\n## Context\\n\\nWe are in search for a means to describe our technical architecture.\\n\\nWe are a small team working in a very lean and agile way (XP), so we naturally\\nprefer also light-weight documentation methods which also accomodate change\\neasily.\\n\\n## Decision\\n\\n- We will use _Architecture Decision Records_, as described by Michael Nygard in\\n  this\\n  [article](http://thinkrelevance.com/blog/2011/11/15/documenting-architecture-decisions).\\n- We will follow the convention of storing those ADRs as Markdown formatted\\n  documents stored under `docs/adr` directory, as exemplified in Nat Pryce\'s\\n  [adr-tools](https://github.com/npryce/adr-tools). This does not imply we will\\n  be using `adr-tools` itself.\\n\\n## Consequences\\n\\nSee Michael Nygard\'s article, linked above."}]}}')}}]);